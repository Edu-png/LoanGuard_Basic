# -*- coding: utf-8 -*-
"""LoanGuard: Basic Decision Tree Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xDlS2tAMNlgzIRnhO0_WbWZyzLAMm_wb

# *LoanGuard: Basic Decision Tree Classifier*

# ü§ì Situa√ß√£o:

Uma empresa de empr√©stimo de autom√≥veis est√° passando por uma situa√ß√£o muito complicada. Ela est√° com uma alta demanda para uma frota reduzida e uma alta taxa de clientes inadimplentes, ou seja, clientes que n√£o pagam o empr√©stimo no tempo devido.

- Alta demanda
- Frota reduzida
- Inadimpl√™ncia

Isso est√° gerando um grande preju√≠zo para a empresa. E n√≥s fomos contratados para ajudar a melhorar essa situa√ß√£o da empresa, para identificar esses clientes inadimplentes antes mesmo da empresa conceder o empr√©stimo do ve√≠culo.

Para resolver essa situa√ß√£o, essa empresa nos forneceu uma base de dados em formato CSV com dados hist√≥ricos de clientes inadimplentes. Vamos utilizar essa base de dados para construir um modelo de intelig√™ncia artificial que vai conseguir classificar os clientes entre adimplentes e inadimplentes.

# üéØ Objetivo:

Criar um modelo de classifica√ß√£o em Machine Learning que permita identificar clientes inadimplentes em uma empresa de empr√©stimo de autom√≥veis evitando prejuizos.

# üèÉ‚Äç‚ôÇÔ∏è Pipeline:

1. Leitura da base de dados que iremos usar:
link: https://cdn3.gnarususercontent.com.br/3069-classificacao/emp_automovel.csv

2. Cria√ß√£o do modelo de classifica√ß√£o que mais se adequa ao nosso caso

3. Valida√ß√£o de modelos
  - Usaremos treino, valida√ß√£o e teste
  - Usaremos Cross Validation (Valida√ß√£o cruzada)

# üöÄ M√£o na massa:

### 1. Importando bibliotecas e lendo o arquivo necess√°rio:
"""

import pandas as pd

dados = pd.read_csv('/content/emp_automovel.csv')

dados.head()

"""Nossa ultima coluna "inadimplente" que j√° est√° em formato num√©rico √© o que queremos identificar (vari√°vel alvo). Repare que a base de dados j√° est√° inteiramente tratada e toda num√©rica, sem ser necess√°rio usar o one_hot_enconder."""

# Separando vari√°vel alvo das explicativas:

y = dados['inadimplente']
y

x = dados.drop('inadimplente', axis = 1)
x

"""Agora que as duas j√° est√£o separadas, podemos seguir com o nosso processo de cria√ß√£o de modelos.

### 2. Divis√£o de treino e teste e valida√ß√£o do nosso grupo

Para validar os nossos dados vamos separar em 3 partes: Treino, teste e valida√ß√£o! Isso funciona para que tenhamos uma maior confian√ßa em rela√ß√£o aos nossos dados.
"""

from sklearn.model_selection import train_test_split

# Vamos ter que dividir 2 vezes para ter os 3 conjuntos:

x, x_teste, y, y_teste = train_test_split(x, y, test_size = 0.15, stratify = y, random_state = 5)
x_treino, x_val, y_treino, y_val = train_test_split(x, y, stratify = y, random_state = 5)

"""### 3. Cria√ß√£o do algortimo: Decision Thee"""

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(x_treino,y_treino)

print(f'Acur√°cia de treino: {model.score(x_treino, y_treino)*100} %')
print(f'Acur√°cia de valida√ß√£o: {model.score(x_val, y_val)*100} %')

"""Vemos que o desempenho est√° caindo muito drasticamente, o que pode indicar que o nosso modelo est√° decorando o padr√£o do teste, o que torna ele inapto para outros conjuntos, para mudar isso, vamos usar o max_depth."""

modelo = DecisionTreeClassifier(max_depth = 10)
modelo.fit(x_treino, y_treino)

print(f'Acur√°cia de treino: {modelo.score(x_treino, y_treino)}')
print(f'Acur√°cia de valida√ß√£o: {modelo.score(x_val, y_val)}')

# Gerando um gr√°fico com as decis√µes:

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize = (20,20))
plot_tree(model, filled = True, class_names = ['n√£o', 'sim'], fontsize = 1, feature_names = dados.columns);

"""### 4. Acur√°cia, precis√£o e recall

Com isso, embora a acurr√¢cia do treino tenha caido, a da valida√ß√£o aumentou significativamente. No entanto, a acur√¢cia nos tr√°s apenas um valor geral, precisamos avaliar especificamente cada uma das classes. Para isso, vamos usar o que chamamos de matriz de confus√£o:
"""

from sklearn.metrics import confusion_matrix

y_previsto = modelo.predict(x_val)
matriz_confusao = confusion_matrix(y_val, y_previsto)
print(matriz_confusao)

"""Vamos melhorar um pouco o aspecto visual desse resultado, pois n√£o da para entender muito no momento"""

from sklearn.metrics import ConfusionMatrixDisplay

viz = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao)
viz.plot();

"""Na coluna temos os valores reais, e na linha os valores previstos. Essa matriz de confus√£o revela que, embora o modelo tenha um bom desempenho ao identificar clientes adimplentes (com apenas 116 falsos positivos), ele tem uma baixa capacidade de identificar clientes inadimplentes, j√° que 960 casos foram classificados incorretamente. Isso indica que o modelo est√° subestimando a quantidade de clientes que n√£o pagariam o empr√©stimo, o que poderia representar um risco significativo para a empresa, uma vez que esses clientes podem n√£o ser identificados a tempo de prevenir perdas financeiras.

- True Positives (TP): O modelo identificou corretamente 42 casos de clientes inadimplentes (1) como inadimplentes.
- True Negatives (TN): O modelo identificou corretamente 10000 casos de clientes adimplentes (0) como adimplentes.
- False Positives (FP): O modelo incorretamente classificou 116 casos de clientes adimplentes (0) como inadimplentes.
- False Negatives (FN): O modelo incorretamente classificou 960 casos de clientes inadimplentes (1) como adimplentes.
"""

# Mudando o 0 e 1 para suas categorias para ficar mais f√°cil interpretar;

viz = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao, display_labels = ['Adimplente', 'Inadimplente'])
viz.plot();

# Calculando Acur√°cia levando isso em conta

from sklearn.metrics import accuracy_score

print(f'Acur√°cia: {accuracy_score(y_val, y_previsto)*100} % ')

# Calculando recall e precis√£o:

from sklearn.metrics import precision_score, recall_score

print(f'Precis√£o: {precision_score(y_val, y_previsto)}')
print(f'Recall: {recall_score(y_val, y_previsto)} ')

"""Isso indica que o nosso modelo n√£o est√° indo muito bem, com valores de precis√£o e recall muito pr√≥ximos a zero - uma melhor m√©trica seria pr√≥xima de 1.

O que vemos como mais importante √© o recall, pois ele pode levar a empresa a um prejuizo e isso √© diretamente relacionado ao nosso problema de neg√≥cios, sendo ele mais relevante vamos levar ele em conta.

Al√©m disso temos o F1 score como outra fun√ß√£o, que nos daria um equilibrio entre essas duas m√©tricas - N√£o perder clientes e n√£o ter preju√≠zos.

###  4.1 f1_score
"""

from sklearn.metrics import f1_score

print(f'F1_score : {f1_score(y_val, y_previsto)}')

"""Esse tamb√©m √© um valor bem baixo, principalmente por conta das outras duas estarem baixas tamb√©m!

### 4.2 Curva ROC

Sendo o recall a m√©trica mais importante, vamos construir gr√°ficos a partir dele para entender melhor o nosso modelo, usando primeiramente a curva ROC para saber se o modelo est√° diferenciando bem uma m√©trica da outra:
"""

from sklearn.metrics import RocCurveDisplay

RocCurveDisplay.from_predictions(y_val, y_previsto, name = '√Årvore de Decis√£o');

"""A curva ROC (Receiver Operating Characteristic Curve) apresentada mostra o desempenho de um modelo de √Årvore de Decis√£o para a classifica√ß√£o de clientes inadimplentes. A linha segue quase uma diagonal perfeita, indicando que o modelo tem pouca ou nenhuma capacidade de discrimina√ß√£o entre as classes positiva e negativa. O valor da AUC (√Årea Sob a Curva - Quanto mais pr√≥ximo de 1 melhor) √© de 0,52, muito pr√≥ximo de 0,5, o que sugere que o modelo est√° classificando os resultados quase aleatoriamente, com desempenho equivalente ao de um classificador que faz suposi√ß√µes aleat√≥rias. O ideial seria uma linha quase reta, pr√≥xima ao 0 do eixo x e o 1 do eixo y.

### 4.2 Curva de precis√£o x Recall
"""

from sklearn.metrics import PrecisionRecallDisplay

PrecisionRecallDisplay.from_predictions(y_val, y_previsto, name = '√Årvore de decis√£o');

"""A curva Precision-Recall exibida demonstra o desempenho de uma √Årvore de Decis√£o no contexto de detec√ß√£o de clientes inadimplentes. A curva apresenta uma queda acentuada na precis√£o logo no in√≠cio, com uma precis√£o alta apenas para baix√≠ssimos valores de recall. Conforme o recall aumenta, a precis√£o rapidamente cai para valores muito baixos, estabilizando-se pr√≥xima a zero. O valor de AP (Average Precision) √© de 0,09 - Quanto mais pr√≥ximo de 1 melhor, o que indica que o modelo tem um desempenho muito fraco na distin√ß√£o entre classes, especialmente em manter a precis√£o enquanto tenta aumentar o recall. Isso sugere que o modelo n√£o √© eficaz em identificar corretamente os clientes inadimplentes sem gerar um grande n√∫mero de falsos positivos.

### 4.3 Avaliando todas ao mesmo tempo

Existe uma forma de avaliarmos tudo ao mesmo tempo e j√° podermos tirar conclus√µes diretas.
"""

from sklearn.metrics import classification_report

print(classification_report(y_val, y_previsto))

"""Com isso vemos que claramente h√° um desequilibrio dos dados, tendo muito mais '0's.

O relat√≥rio de classifica√ß√£o indica que o modelo de √Årvore de Decis√£o possui uma alta precis√£o geral (91%), mas falha significativamente na identifica√ß√£o de clientes inadimplentes. Embora o modelo consiga identificar corretamente 99% dos clientes que n√£o s√£o inadimplentes (classe 0) e tenha uma precis√£o de 92% para essa classe, ele apresenta um desempenho muito fraco para a classe 1 (inadimplentes), com uma precis√£o de apenas 27% e um recall extremamente baixo de 4%, resultando em um F1-score de apenas 0,07. Esses resultados sugerem que, apesar da alta acur√°cia geral, o modelo √© ineficaz para a tarefa espec√≠fica de detectar inadimplentes, provavelmente devido ao desequil√≠brio de classes, onde a classe 0 domina, mascarando a verdadeira performance do modelo para a classe minorit√°ria.

### 4.4 Usando o KFOLD para valida√ß√£o cruzada

Ao invez de dividir esses dados apenas em treino, valida√ß√£o e teste, vamos usar o KFOLD para criar esses grupos de forma aleat√≥ria e testar K vezes para adequar ao processo de forma aleat√≥ria, o que garante que nossos conjuntos sejam mais homog√™neos.
"""

from sklearn.model_selection import cross_validate, KFold

modelo = DecisionTreeClassifier(max_depth = 10)
kf = KFold(n_splits = 5, shuffle = True, random_state = 5)
cv_resultados = cross_validate(modelo, x, y, cv = kf)
cv_resultados

# Pegando os valores isolados de resultados do test score:

cv_resultados['test_score']

# Calculando algumas m√©tricas em cima desses valores:

media = cv_resultados['test_score'].mean()
desvio_padrao = cv_resultados['test_score'].std()
print(f'Intervalo de confian√ßa de: [{media - 2*desvio_padrao}, {media + 2* desvio_padrao}]') #Minimo e m√°ximo s√£o a m√©dia + ou - 2x o desvio padr√£o.

"""Vemos que nosso intervalo de confian√ßa apresenta um desempenho entre 89 e 91% de acur√°cia, no entanto, o que queremos √© o recall.

### 4.5 Valida√ß√£o cruzada com recall
"""

def intervalo_conf(resultados):
  media = resultados['test_score'].mean()
  desvio_padrao = resultados['test_score'].std()
  print(f'Intervalo de confian√ßa de: [{media - 2*desvio_padrao} - {media + 2* desvio_padrao}]') #Minimo e m√°ximo s√£o a m√©dia + ou - 2x o desvio padr√£o.

# Usando o recall:

modelo = DecisionTreeClassifier(max_depth = 10)
kf = KFold(n_splits = 5, shuffle = True, random_state = 5)
cv_resultados = cross_validate(modelo, x, y, cv = kf, scoring = 'recall')
cv_resultados

intervalo_conf(cv_resultados)

"""Ainda estamos com valores baixos, mas isso, como vimos √© por conta da despropor√ß√£o de dados entre clientes adimplentes e inadimplentes. Vamos checar a propor√ß√£o e identificar como separar se forma melhor no cross validate."""

dados['inadimplente'].value_counts(normalize = True)

"""91 % dos nossos dados s√£o relacionados a clientes inadimplentes, ou seja, uma propor√ß√£o significamente maior, e isso interfere muito no modelo. Portanto, precisamos estratificar melhor esses dados."""

from sklearn.model_selection import StratifiedKFold

modelo = DecisionTreeClassifier(max_depth = 10)
skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 5)
cv_resultados = cross_validate(modelo, x, y, cv = skf, scoring = 'recall')

intervalo_conf(cv_resultados)

"""Vemos que nossa margem est√° muito melhor, mas o modelo ainda n√£o est√° bom, como melhorar?

- Primeiro temos que lidar com a quest√£o do Oversampling (Devido a falta de balanceamento dos dados), para isso, vamos tentar equilibrar esses dados.

### 4.6 Oversampling

O oversampling (sobreamostragem) normal, que seria o aleat√≥rio, duplica a quantidade de elementos da classe de menor quantidade de forma aleat√≥ria.

Por√©m, vamos utilizar um m√©todo conhecido como SMOTE (Synthetic Minority Over-sampling Technique ou t√©cnica de sobreamostragem minorit√°ria sint√©tica). √â um algoritmo que, ao inv√©s de simplesmente duplicar os elementos da classe de menor quantidade, cria novos dados sint√©ticos com padr√£o semelhante aos dados que j√° existem.
"""

from imblearn.over_sampling import SMOTE

oversample = SMOTE()
x_balanceado, y_balanceado = oversample.fit_resample(x,y)

y_balanceado.value_counts(normalize = True)

"""Balanceou 50 - 50 %, vamos agora treinar o modelo novamente!"""

# Treinando o novo modelo:

modelo = DecisionTreeClassifier(max_depth = 10)
skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 5)
cv_resultados = cross_validate(modelo, x_balanceado, y_balanceado, cv = skf, scoring = 'recall')

intervalo_conf(cv_resultados)

"""Vemos que o desempenho est√° muito melhor, mas avaliamos nos dados balanceados, e no mundo real n√£o est√° assim, ent√£o temos que avaliar em conjuntos n√£o balanceados. Para isso, vamos usar um pipeline de dados:

### 4.7 Pipeline dos dados

 Um pipeline √© uma sequ√™ncia de transforma√ß√µes, opera√ß√µes que realizamos nos dados.
"""

from imblearn.pipeline import Pipeline as imbpipeline

modelo = DecisionTreeClassifier(max_depth = 10)

pipeline = imbpipeline([('oversample', SMOTE()), ('arvore', modelo)])

skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 5)
cv_resultados = cross_validate(pipeline, x, y, cv = skf, scoring = 'recall')

intervalo_conf(cv_resultados)

"""O nosso intervalo de confian√ßa ja caiu bastante, mas o nosso processo est√° de fato mais correto e no seu uso indicado. √â melhor que o nosso recall de antes, mas ainda √© um valor baixo.

### 4.8 Undersampling (subamostragem)

Ao inv√©s de aumentar a quantidade de dados da classe que tem menor quantidade, vamos fazer o contr√°rio. Reduziremos a quantidade de dados da classe que tem maior quantidade, at√© que ela tenha a mesma quantidade de dados que a classe com a menor quantidade.

Existe um processo de undersampling aleat√≥rio que n√£o utiliza nenhum crit√©rio para a remo√ß√£o dos dados. Ele simplesmente remove dados aleatoriamente da base de dados da classe que tem maior quantidade. Por√©m, esse processo n√£o √© t√£o recomendado porque pode ser que, durante esse processo, dados importantes para o modelo compreender o padr√£o dos dados sejam perdidos.

Ao inv√©s do undersampling aleat√≥rio, vamos aplicar outra t√©cnica de undersampling que se chama NearMiss. Nessa estrat√©gia, h√° um crit√©rio de escolher os elementos que v√£o continuar na base de dados que tenham um padr√£o bem parecido com os elementos que j√° existem na outra classe.
"""

from imblearn.under_sampling import NearMiss

modelo = DecisionTreeClassifier(max_depth = 10)
pipeline = imbpipeline([('undersample', NearMiss(version = 3)), ('arvore', modelo)])

skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 5)
cv_resultados = cross_validate(pipeline, x, y, cv = skf, scoring = 'recall')

intervalo_conf(cv_resultados)

"""Usando essa estrat√©gia, nosso resultado j√° melhorou de forma significativa, ent√£o vamos usar isso no nosso modelo final que vamos validar agora no nosso conjunto de teste!

## 5. Testando o nosso modelo:

Selecionamos o modelo que apresentou o melhor desempenho utilizando a estrat√©gia de undersampling com o algoritmo NearMiss na vers√£o 3. Este algoritmo ir√° balancear nossos dados e, a partir deles, vamos treinar o modelo com base nos dados para identificar o padr√£o de cada uma das classes.
"""

undersample = NearMiss(version = 3)
x_balanceado, y_balanceado = undersample.fit_resample(x, y)

modelo = DecisionTreeClassifier(max_depth = 10)
modelo.fit(x_balanceado, y_balanceado)
y_previsto = modelo.predict(x_teste)

print(classification_report(y_teste, y_previsto))
ConfusionMatrixDisplay.from_predictions(y_teste, y_previsto);

"""O relat√≥rio de classifica√ß√£o e a matriz de confus√£o indicam que o modelo est√° enfrentando dificuldades em distinguir corretamente entre as classes. Para a classe 0, a precis√£o √© alta (94%), mas o recall √© baixo (48%), significando que o modelo deixa de identificar muitos casos verdadeiros de classe 0. J√° para a classe 1, a precis√£o √© muito baixa (11%), embora o recall seja relativamente bom (70%), mostrando que o modelo identifica a maioria dos casos de classe 1, mas com muitos falsos positivos. A acur√°cia geral √© de apenas 50%, refletindo o baixo desempenho do modelo. A matriz de confus√£o refor√ßa esses problemas, mostrando um grande n√∫mero de falsos positivos para a classe 0 e falsos negativos para a classe 1. Isso sugere que o modelo est√° enviesado e precisa de ajustes, como balanceamento de dados ou altera√ß√£o do limiar de classifica√ß√£o, para melhorar sua performance geral."""

